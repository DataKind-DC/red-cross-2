{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcboe72\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mcboe72\\\\Documents\\\\GitHub\\\\red-cross-2\\\\Model-1B'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn import linear_model\n",
    "\n",
    "#This is old and causes warnings - updated with sklearn.model_selection\n",
    "# from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "#from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import normalize, Imputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "#Get the working directory\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "#Change the working directory and confirm it changed to where you want it to be!\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\mcboe72\\\\Documents\\\\GitHub\\\\red-cross-2\\\\Model-1B')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs = pd.read_csv('http://enigma-public.s3.amazonaws.com/projects/smoke-alarm-risk/data/acs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tractid</th>\n",
       "      <th>all_fire_all_years</th>\n",
       "      <th>alarm_unknown_all_years</th>\n",
       "      <th>alarm_presented_all_years</th>\n",
       "      <th>alarm_not_presented_all_years</th>\n",
       "      <th>ratio_no_alarm_in_all</th>\n",
       "      <th>ratio_no_alarm_in_all_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tractid  all_fire_all_years  alarm_unknown_all_years  \\\n",
       "0  1001020100                   4                        0   \n",
       "1  1001020200                   8                        1   \n",
       "2  1001020300                   7                        2   \n",
       "3  1001020400                   8                        4   \n",
       "4  1001020500                  15                        5   \n",
       "\n",
       "   alarm_presented_all_years  alarm_not_presented_all_years  \\\n",
       "0                          4                              0   \n",
       "1                          3                              4   \n",
       "2                          0                              5   \n",
       "3                          2                              2   \n",
       "4                          7                              3   \n",
       "\n",
       "   ratio_no_alarm_in_all  ratio_no_alarm_in_all_known  \n",
       "0               0.000000                     0.000000  \n",
       "1               0.500000                     0.571429  \n",
       "2               0.714286                     1.000000  \n",
       "3               0.250000                     0.500000  \n",
       "4               0.200000                     0.300000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tract_data = pd.read_csv('https://raw.githubusercontent.com/maria-brun/red-cross-2/master/2009_2013_alarm_presence_by_tract.csv')\n",
    "del tract_data['Unnamed: 0']\n",
    "tract_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geoid is a code that indicates the summary level, the state, county, etc \n",
    "For reference, see the documentation at this website: https://www.census.gov/geo/reference/geoidentifiers.html \n",
    "\n",
    "The number of digits determins the level: 2 for state, 5 for state and county, 10 for state and county and county subdivision, etc \n",
    "\n",
    "This code splits the column geoid into tract ids - parsed ID and sum level \n",
    "As an example, I output the full geoid and the parsed ID and sum level for the 100th observation in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578840    53033027300\n",
       "578841    53057952100\n",
       "578842    53063012300\n",
       "578866    55007960200\n",
       "578867    55079017000\n",
       "Name: geoid_parsed, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# GETTING THE TRACT ID:\n",
    "########################################\n",
    "\n",
    "x = acs['geoid'][100]\n",
    "parsed_id = x.split('US')[1]\n",
    "sum_level = x.split('US')[0]\n",
    "\n",
    "\n",
    "\n",
    "acs['geoid_parsed'] = [geo[1] for geo in acs['geoid'].str.split('US')]\n",
    "acs['sum_level'] = [geo[0] for geo in acs['geoid'].str.split('US')]\n",
    "\n",
    "# understanding census coding: https://www.census.gov/geo/reference/geoidentifiers.html\n",
    "# sumlevel == 15000 is block group\n",
    "# sumlevel == 14000 is census tract\n",
    "# sumlevel == 05000 is county\n",
    "\n",
    "# pulling out state and county for ease of use\n",
    "#acs['state'] = acs['geoid_parsed'].str[0:2]\n",
    "#acs['cnty'] = acs['geoid_parsed'].str[2:5]\n",
    "#acs['raw_tract'] = acs['geoid_parsed'].str[5:]\n",
    "\n",
    "#acsC = acs.query(\"sum_level == '05000' \")\n",
    "acsCT = acs.query(\"sum_level == '14000'\")\n",
    "\n",
    "acsCT['geoid'].tail()\n",
    "#acsCT['state'].tail()\n",
    "#acsCT['cnty'].tail()\n",
    "#acsCT['raw_tract'].tail()\n",
    "acsCT['geoid_parsed'].tail()\n",
    "# Only need to keep the tract level, so clear some space in memory\n",
    "#del acs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#### upsample at arbitrary threshold for testing\\nfrom sklearn.utils import resample\\nhigh_fires_resampled = resample(tract_data_merged_filtered.query( \"all_fire_all_years >= 50\" ), n_samples = 1000, random_state = 12)\\ntract_data_merged_filtered = tract_data_merged_filtered.append(high_fires_resampled)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "########################################\n",
    "# MERGING PREDICTORS & TARGET VARIABLE:\n",
    "########################################\n",
    "\n",
    "\n",
    "acsCT = acsCT.rename(columns = {'geoid_parsed':'tractid'})\n",
    "acsCT['tractid'] = acsCT['tractid'].astype('int64')\n",
    "acs_tractid = acsCT['tractid']\n",
    "\n",
    "acsCT.query(\" tractid == 56043000200 \")\n",
    "acsCT = acsCT.drop(['sum_level', 'geoid'], axis = 1)\n",
    "\n",
    "#acsCT.dropna()\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "# Handle missing observations by simple mean imputation\n",
    "acs_features = acsCT.drop(['tractid'], axis = 1)\n",
    "\n",
    "col_names = acs_features.columns\n",
    "\n",
    "imp = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0).fit(acs_features)\n",
    "acs_features = imp.transform(acs_features)\n",
    "\n",
    "acsCT = pd.DataFrame(acs_features)\n",
    "acsCT.columns = col_names\n",
    "acsCT = pd.concat([acsCT.reset_index(drop=True), acs_tractid.reset_index(drop=True)], axis = 1)\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "tract_data['tractid'].tail()\n",
    "tract_data_merged = tract_data.merge(acsCT, how='left', on='tractid')\n",
    "#tract_data_merged.tail()\n",
    "\n",
    "tract_data_merged.isnull().sum()\n",
    "\n",
    "\n",
    "#tract_data_merged_filtered = tract_data_merged.query(\" all_fire_all_years > 25 \").dropna()\n",
    "tract_data_merged_filtered = tract_data_merged.query(\" all_fire_all_years > 25 \")\n",
    "\n",
    "#for x in tract_data_merged_filtered.columns:\n",
    "#    print(x)\n",
    "\n",
    "tract_data_merged_filtered.isnull().sum()\n",
    "\n",
    "\n",
    "'''\n",
    "#### upsample at arbitrary threshold for testing\n",
    "from sklearn.utils import resample\n",
    "high_fires_resampled = resample(tract_data_merged_filtered.query( \"all_fire_all_years >= 50\" ), n_samples = 1000, random_state = 12)\n",
    "tract_data_merged_filtered = tract_data_merged_filtered.append(high_fires_resampled)\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# Model Preparation\n",
    "########################################\n",
    "\n",
    "\n",
    "data_features = tract_data_merged_filtered.drop('ratio_no_alarm_in_all', axis = 1)\n",
    "data_features = data_features.drop(['tractid', 'alarm_unknown_all_years',\n",
    "                                    'alarm_presented_all_years', 'alarm_not_presented_all_years',\n",
    "                                    'ratio_no_alarm_in_all_known'], axis = 1)\n",
    "data_target = tract_data_merged_filtered['ratio_no_alarm_in_all']\n",
    "\n",
    "data_features.isnull().sum()\n",
    "\n",
    "\n",
    "# Handle missing observations by simple mean imputation\n",
    "col_names = data_features.columns\n",
    "imp = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0).fit(data_features)\n",
    "data_features = imp.transform(data_features)\n",
    "\n",
    "data_features = pd.DataFrame(data_features)\n",
    "data_features.columns = col_names\n",
    "\n",
    "data_features.isnull().sum()\n",
    "\n",
    "\n",
    "#observation_weights = data_features.all_fire_all_years/data_features.all_fire_all_years.sum()\n",
    "#observation_weights_normalized = normalize(observation_weights, norm = 'l1')\n",
    "#data_features = data_features.drop(['all_fire_all_years'], axis = 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_features,\n",
    "                                                    data_target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=12)\n",
    "\n",
    "all_fires = x_train.all_fire_all_years\n",
    "\n",
    "observation_weights = x_train.all_fire_all_years/x_train.all_fire_all_years.sum()\n",
    "#observation_weights_normalized = normalize(observation_weights, norm = 'l1').ravel()\n",
    "scaled_weights = x_train.all_fire_all_years/np.max(x_train.all_fire_all_years)\n",
    "\n",
    "x_train = x_train.drop(['all_fire_all_years'], axis = 1)\n",
    "x_test = x_test.drop(['all_fire_all_years'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# Output to csv\n",
    "x_train.to_csv('x_train.csv', header = True, index = False)\n",
    "x_test.to_csv('x_test.csv', header = True, index = False)\n",
    "y_train.to_csv('y_train.csv', header = True, index = False)\n",
    "y_test.to_csv('y_test.csv', header = True, index = False)\n",
    "all_fires.to_csv('all_fires.csv', header = True, index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcboe72\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15035632560579218\n",
      "0.23830587738991435\n",
      "43320    0.047686\n",
      "52906    0.060209\n",
      "2372     0.158454\n",
      "2371     0.026863\n",
      "15018    0.166931\n",
      "Name: weighted_linear_pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################\n",
    "# MODELING\n",
    "########################################\n",
    "\n",
    "\n",
    "clf_linear = linear_model.SGDRegressor(loss = 'squared_loss', penalty = 'none', random_state = 12)\n",
    "clf_linear.fit(x_train, y_train, sample_weight=scaled_weights)\n",
    "#clf_linear.fit(x_train, y_train, sample_weight=observation_weights_normalized)\n",
    "#clf_linear.fit(x_train, y_train)\n",
    "#clf_linear = linear_model.LogisticRegression()\n",
    "#clf_linear.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf_linear.predict(x_test)\n",
    "\n",
    "\n",
    "# RMSE of simple linear model\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(rmse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Use model to predict for every census tract in the geocoded data (68075) ####\n",
    "\n",
    "# Clean up original full dataset\n",
    "tract_data_merged_simple = tract_data_merged.drop(['tractid', 'alarm_unknown_all_years',\n",
    "                                    'alarm_presented_all_years', 'alarm_not_presented_all_years',\n",
    "                                    'ratio_no_alarm_in_all_known', 'ratio_no_alarm_in_all', 'all_fire_all_years'], axis = 1)\n",
    "\n",
    "\n",
    "#tract_data_merged_simple_clean = tract_data_merged.dropna()\n",
    "#tract_data_merged_simple = tract_data_merged_simple_clean.drop(['tractid', 'sum_level', 'geoid', 'alarm_unknown_all_years',\n",
    "#                                    'alarm_presented_all_years', 'alarm_not_presented_all_years',\n",
    "#                                    'ratio_no_alarm_in_all_known', 'ratio_no_alarm_in_all', 'all_fire_all_years'], axis = 1)\n",
    "\n",
    "                               \n",
    "\n",
    "tract_data_merged_simple.isnull().sum()\n",
    "\n",
    "# Handle missing observations by simple mean imputation\n",
    "col_names = tract_data_merged_simple.columns\n",
    "imp = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0).fit(tract_data_merged_simple)\n",
    "tract_data_merged_simple = imp.transform(tract_data_merged_simple)\n",
    "\n",
    "tract_data_merged_simple = pd.DataFrame(tract_data_merged_simple)\n",
    "tract_data_merged_simple.columns = col_names                                    \n",
    "                  \n",
    "tract_data_merged_simple.isnull().sum()\n",
    "                  \n",
    "full_preds = clf_linear.predict(tract_data_merged_simple)\n",
    "\n",
    "### Bound probabilities\n",
    "#full_preds[full_preds < 0] = 0\n",
    "#full_preds[full_preds > 1] = 1\n",
    "\n",
    "\n",
    "# RMSE of simple linear model on the full dataset\n",
    "#print sqrt(mean_squared_error(tract_data_merged_simple_clean.ratio_no_alarm_in_all, full_preds))\n",
    "print (sqrt(mean_squared_error(tract_data_merged.ratio_no_alarm_in_all, full_preds)))\n",
    "\n",
    "\n",
    "#tract_data['weighted_linear_pred'] = full_preds\n",
    "tract_data['weighted_linear_pred'] = full_preds\n",
    "#tract_data_merged['weighted_linear_pred'] = full_preds\n",
    "\n",
    "tract_data = tract_data.sort_values(['all_fire_all_years'], ascending = False)\n",
    "\n",
    "\n",
    "tract_data['weighted_linear_pred'].describe()\n",
    "print(tract_data['weighted_linear_pred'].tail())\n",
    "\n",
    "# Output to csv\n",
    "tract_data.to_csv('tract_data_weighted_linear_preds_upsampled_REPLICATION.csv', header = True, index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#### Use model to predict for every census tract in the census data (74,001) ####\n",
    "\n",
    "full_preds_acsCT = clf_linear.predict(acs_features)\n",
    "\n",
    "### Bound probabilities\n",
    "#full_preds[full_preds < 0] = 0\n",
    "#full_preds[full_preds > 1] = 1\n",
    "\n",
    "\n",
    "# Can't compute RMSE because we have no target for some of the tracts.\n",
    "\n",
    "tract_preds_74k = pd.concat([acs_tractid.reset_index(drop=True), pd.Series(full_preds_acsCT)], axis = 1)\n",
    "\n",
    "tract_preds_74k.columns = ['tractid', 'weighted_linear_pred']\n",
    "\n",
    "tract_preds_74k.weighted_linear_pred.describe()\n",
    "\n",
    "\n",
    "# Output to csv\n",
    "tract_preds_74k.to_csv('tracts_74k_weighted_linear_preds_upsampled_REPLICATION.csv', header = True, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
